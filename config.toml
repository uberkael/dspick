[llm]
types = [
    "google",
    "openai",
    "ollama",
    "grok",
    "mistral",
    "anthropic",
    "azure",
]
cache = true
model = "gemini/gemini-2.5-flash-lite-preview-06-17"
type = "google"
rpm = 15
throttling = true

[ollama]
models = [
    "ollama/deepseek-r1",
    "ollama/deepseek-v2",
    "ollama/gemma3",
    "ollama/mistral",
    "ollama/qwen3",
]

[google]
models = [
    "gemini/gemini-2.5-pro",
    "gemini/gemini-2.5-flash-lite-preview-06-17",
]
